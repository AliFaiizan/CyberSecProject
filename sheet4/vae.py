#!/usr/bin/env python3
"""
Train TWO VAEs for Task Sheet 4 using REAL HAI-22.04 dataset

CRITICAL: VAE is trained on REAL data, then used to extract features from:
  - Synthetic training data (generated by GAN per fold)
  - Real test data (for evaluation)

This is the correct approach for Task Sheet 4!
"""

import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from glob import glob

# Importing VAE code
from task1 import (
    VAE,
    train_vae_reconstruction,
    train_vae_classification,
    extract_latent_features
)
from utils import load_data, create_windows_for_vae


def train_vae_for_mode(mode, X, y, M, F, device):
    """
    Train VAE for either reconstruction or classification mode
    
    Args:
        mode: 'reconstruction' or 'classification'
        X: Raw REAL data (normalized)
        y: REAL labels
        M: Window size
        F: Feature dimension
        device: torch device
    
    Returns:
        model: Trained VAE
        checkpoint_dict: Dictionary to save
    """
    print("\n" + "="*70)
    print(f"TRAINING VAE - {mode.upper()} MODE (on REAL data)")
    print("="*70)
    
    layer_type = 'dense'
    activation = 'relu'
    latent_dim = 8
    epochs = 10
    batch_size = 128
    
    # ==========================================
    # Create Windows from REAL data
    # ==========================================
    print(f"\nCreating windows from REAL HAI-22.04 data (mode={mode})...")
    
    if mode == "reconstruction":
        X_win, _ = create_windows_for_vae(X, y, M, mode="reconstruction")
        y_win = None
        print(f"  Windows: {X_win.shape[0]} (only normal)")
    else:
        X_win, y_win = create_windows_for_vae(X, y, M, mode="classification")
        print(f"  Windows: {X_win.shape[0]}")
        print(f"  Normal: {np.sum(y_win == 0)}, Attack: {np.sum(y_win == 1)}")
    
    # Flatten for dense VAE
    X_flat = X_win.reshape(X_win.shape[0], -1)
    dense_input_dim = X_flat.shape[1]  # M * F
    
    # Train/val split
    if mode == "reconstruction":
        X_train, X_val = train_test_split(
            X_flat, test_size=0.2, random_state=42, shuffle=True
        )
        y_train = y_val = None
    else:
        X_train, X_val, y_train, y_val = train_test_split(
            X_flat, y_win, test_size=0.2, random_state=42, shuffle=True
        )
    
    print(f"Train: {X_train.shape}, Val: {X_val.shape}")
    
    # ==========================================
    # Build VAE
    # ==========================================
    print("\nBuilding VAE...")
    
    model = VAE(
        input_dim=dense_input_dim,
        latent_dim=latent_dim,
        layer_type=layer_type,
        activation=activation,
        num_classes=None if mode == "reconstruction" else 2,
        seq_len=M,
        feature_dim=F,
    )
    
    # ==========================================
    # Create DataLoaders
    # ==========================================
    if mode == "reconstruction":
        train_loader = DataLoader(
            TensorDataset(torch.from_numpy(X_train).float()),
            batch_size=batch_size,
            shuffle=True,
        )
        val_loader = DataLoader(
            TensorDataset(torch.from_numpy(X_val).float()),
            batch_size=batch_size,
            shuffle=False,
        )
    else:
        train_loader = DataLoader(
            TensorDataset(
                torch.from_numpy(X_train).float(),
                torch.from_numpy(y_train).long()
            ),
            batch_size=batch_size,
            shuffle=True,
        )
        val_loader = DataLoader(
            TensorDataset(
                torch.from_numpy(X_val).float(),
                torch.from_numpy(y_val).long()
            ),
            batch_size=batch_size,
            shuffle=False,
        )
    
    # ==========================================
    # Train
    # ==========================================
    print(f"\nTraining {mode} VAE on REAL HAI-22.04 data...")
    
    if mode == "reconstruction":
        result = train_vae_reconstruction(
            model, train_loader, val_loader,
            device=device, epochs=epochs, lr=1e-3, recon_type="mse"
        )
    else:
        result = train_vae_classification(
            model, train_loader, val_loader,
            device=device, epochs=epochs, lr=1e-3
        )
    
    print(f"Training complete! Best val loss: {result['best_val_loss']:.6f}")
    
    # ==========================================
    # Prepare checkpoint
    # ==========================================
    checkpoint = {
        'model_state_dict': model.state_dict(),
        'layer_type': layer_type,
        'activation': activation,
        'latent_dim': latent_dim,
        'window_size': M,
        'feature_dim': F,
        'input_dim': dense_input_dim,
        'mode': mode,
        'best_val_loss': result['best_val_loss'],
    }
    
    return model, checkpoint


def main():
    print("\n" + "="*70)
    print("TRAINING VAEs FOR TASK SHEET 4")
    print("="*70)
    print("\nThese VAEs will extract features from:")
    print("  - Synthetic data (GAN-generated) for training")
    print("  - Real data for testing")
    
    # ==========================================
    # Configuration
    # ==========================================
    M = 20  # Window size
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"\nDevice: {device}")
    
    # ==========================================
    # Load REAL HAI-22.04 Data
    # ==========================================
    print("\n" + "="*70)
    print("LOADING REAL HAI-22.04 DATA")
    print("="*70)
    
    train_files = sorted(glob("../datasets/hai-22.04/train1.csv"))
    test_files = sorted(glob("../datasets/hai-22.04/test1.csv"))
    
    if not train_files or not test_files:
        print("\n ERROR: HAI-22.04 dataset not found!")
        print("Expected location: ../datasets/hai-22.04/")
        print("\nPlease ensure you have:")
        print("  - ../datasets/hai-22.04/train1.csv")
        print("  - ../datasets/hai-22.04/test1.csv")
        return
    
    print(f"Found {len(train_files)} training files")
    print(f"Found {len(test_files)} test files")
    
    X, y = load_data(train_files, test_files)
    T, F = X.shape
    
    print(f"\nRaw REAL data loaded:")
    print(f"  Total samples: {T}")
    print(f"  Features: {F}")
    print(f"  Normal: {np.sum(y == 0)}")
    print(f"  Attack: {np.sum(y == 1)}")
    
    # ==========================================
    # Normalize REAL data
    # ==========================================
    print("\nNormalizing REAL data...")
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    print("Normalized using StandardScaler")
    
    # Save the scaler (will be used for synthetic data too)
    import pickle
    with open('vae_scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    print("Saved scaler to vae_scaler.pkl")

    model_recon, checkpoint_recon = train_vae_for_mode(
        "reconstruction", X, y, M, F, device
    )
    
    save_path_recon = "vae_reconstruction_real.pt"
    torch.save(checkpoint_recon, save_path_recon)
    print(f"\n✓ Saved to: {save_path_recon}")
    
    model_class, checkpoint_class = train_vae_for_mode(
        "classification", X, y, M, F, device
    )
    
    save_path_class = "vae_classification_real.pt"
    torch.save(checkpoint_class, save_path_class)
    print(f"\n✓ Saved to: {save_path_class}")
    
    # ==========================================
    # Verification
    # ==========================================
    print("\n" + "="*70)
    print("VERIFICATION")
    print("="*70)
    
    # Test reconstruction VAE
    print("\n1. Reconstruction VAE:")
    checkpoint = torch.load(save_path_recon, map_location='cpu')
    print(f"   Mode: {checkpoint['mode']}")
    print(f"   Latent dim: {checkpoint['latent_dim']}")
    print(f"   Trained on: REAL HAI-22.04 data")
    print(f"   Val loss: {checkpoint['best_val_loss']:.6f}")
    
    # Test classification VAE
    print("\n2. Classification VAE:")
    checkpoint = torch.load(save_path_class, map_location='cpu')
    print(f"   Mode: {checkpoint['mode']}")
    print(f"   Latent dim: {checkpoint['latent_dim']}")
    print(f"   Trained on: REAL HAI-22.04 data")
    print(f"   Val loss: {checkpoint['best_val_loss']:.6f}")
    
    # ==========================================
    # Summary
    # ==========================================
    print("\n" + "="*70)
    print("SUCCESS!")
    print("="*70)
    print(f"\nCreated files:")
    print(f"  1. {save_path_recon} - VAE trained on REAL data")
    print(f"  2. {save_path_class} - VAE trained on REAL data")
    print(f"  3. vae_scaler.pkl - Scaler for consistency")
    
    print(f"\nThese VAEs will be used to extract features from:")
    print(f"  - Synthetic data (from GAN) → for training classifiers")
    print(f"  - Real data → for testing classifiers")
    
    print(f"\nNext steps:")
    print(f"\nScenario 1 (Anomaly Detection):")
    print(f"  python task2_sheet4.py -sc 1 -k 5 -M 20 \\")
    print(f"    --vae-checkpoint {save_path_recon}")
    
    print(f"\nScenarios 2 & 3 (Binary Classification):")
    print(f"  python task2_sheet4.py -sc 2 -k 5 -M 20 \\")
    print(f"    --vae-checkpoint {save_path_class}")
    print(f"  python task2_sheet4.py -sc 3 -k 5 -M 20 \\")
    print(f"    --vae-checkpoint {save_path_class}")
    
    print("\n" + "="*70 + "\n")


if __name__ == "__main__":
    main()