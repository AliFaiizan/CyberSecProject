{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading & Cleaning Data ===\n",
      "Loading ../datasets/haiend-23.05\\end-train1.csv...\n",
      "  Original shape: (280800, 226)\n",
      "Loading ../datasets/haiend-23.05\\end-train2.csv...\n",
      "  Original shape: (291600, 226)\n",
      "Loading ../datasets/haiend-23.05\\end-train3.csv...\n",
      "  Original shape: (126000, 226)\n",
      "Loading ../datasets/haiend-23.05\\end-train4.csv...\n",
      "  Original shape: (198000, 226)\n",
      "Loading ../datasets/haiend-23.05\\end-test1.csv...\n",
      "  Original shape: (54000, 226)\n",
      "Loading ../datasets/haiend-23.05\\end-test2.csv...\n",
      "  Original shape: (230400, 226)\n",
      "Loading labels from ../datasets/haiend-23.05\\label-test1.csv...\n",
      "Loading labels from ../datasets/haiend-23.05\\label-test2.csv...\n",
      "['2022-08-17 00:00:55', '2022-08-17 00:00:56', '2022-08-17 00:00:57', '2022-08-17 00:00:58', '2022-08-17 00:00:59', '2022-08-17 00:01:00', '2022-08-17 00:01:01', '2022-08-17 00:01:02', '2022-08-17 00:01:03', '2022-08-17 00:01:04', '2022-08-17 00:01:05']\n",
      "230395    2022-08-19 15:59:55\n",
      "230396    2022-08-19 15:59:56\n",
      "230397    2022-08-19 15:59:57\n",
      "230398    2022-08-19 15:59:58\n",
      "230399    2022-08-19 15:59:59\n",
      "Name: timestamp, dtype: object\n",
      "labels acount where attack = 1: 11384\n",
      "  Labels merged. Test shape: (284400, 227)\n",
      "  Attack rows in labels: 5679\n",
      "Final training data shape: (896400, 226)\n",
      "Final test data shape: (284400, 226)\n",
      "Total attack rows in merged dataset: 5679\n"
     ]
    }
   ],
   "source": [
    "from utils import load_and_clean_data\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_files = sorted(glob(\"../datasets/hai-22.04/end-train*.csv\"))\n",
    "test_files = sorted(glob(\"../datasets/hai-22.04/end-test*.csv\"))\n",
    "# label_files = sorted(glob(\"../datasets/hai-22.04/label-test*.csv\"))\n",
    "\n",
    "haiEnd_df = load_and_clean_data(train_files, test_files, attack_cols=None) # merge train and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0fefb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in combined train and test data: 1180800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Get all train and test file paths\n",
    "train_files = sorted(glob(\"../datasets/hai-23.05/hai-train*.csv\"))\n",
    "test_files = sorted(glob(\"../datasets/hai-23.05/hai-test*.csv\"))\n",
    "\n",
    "# Load and concatenate train files\n",
    "train_dfs = [pd.read_csv(f) for f in train_files]\n",
    "train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "\n",
    "# Load and concatenate test files\n",
    "test_dfs = [pd.read_csv(f) for f in test_files]\n",
    "test_df = pd.concat(test_dfs, ignore_index=True)\n",
    "\n",
    "# Combine train and test data\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Print total number of rows\n",
    "print(f\"Total rows in combined train and test data: {combined_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f679ff23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DM-PP01-R', 'DM-FT01Z', 'DM-FT02Z', 'DM-FT03Z', '1001.2-OUT',\n",
       "       '1001.7-OUT1', '1001.7-OUT2', '1001.8-OUT', '1002.2-OUT', '1002.6-OUT',\n",
       "       ...\n",
       "       'DM-PCV01-Z', 'DM-PCV02-D', 'DM-PCV02-Z', 'DM-PIT01', 'DM-PIT02',\n",
       "       'DM-PWIT-03', 'DM-TIT01', 'DM-TIT02', 'DM-TWIT-03', 'label'],\n",
       "      dtype='object', length=226)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiEnd_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f32ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = haiEnd_df.drop(columns=['label', 'timestamp'], errors='ignore') # label here refers to attack label 0 or 1\n",
    "y = haiEnd_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a064eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attack_types(y: pd.Series):\n",
    "    \"\"\"\n",
    "    Given a binary label Series y (0=normal, 1=attack),\n",
    "    returns:\n",
    "      - attack_type: per-row integer attack ID (0=normal, 1..N=attack periods)\n",
    "      - intervals: table listing each attack period\n",
    "    \"\"\"\n",
    "    # Make sure y is a Series of ints 0/1\n",
    "    y_bin = (y.astype(int) != 0).astype(int)\n",
    "    \n",
    "    # Detect transitions\n",
    "    prev = y_bin.shift(1, fill_value=0)\n",
    "    change = y_bin - prev\n",
    "    \n",
    "    # Attack start and end indices\n",
    "    start_idx = y_bin.index[change == 1].tolist()\n",
    "    end_idx   = y_bin.index[change == -1].tolist()\n",
    "    \n",
    "    # If the last row is still attack, close it\n",
    "    if len(end_idx) < len(start_idx):\n",
    "        end_idx.append(y_bin.index[-1])\n",
    "    \n",
    "    # Build intervals table\n",
    "    intervals = pd.DataFrame({\n",
    "        \"attack_id\": range(1, len(start_idx)+1),\n",
    "        \"start_index\": start_idx,\n",
    "        \"end_index\": end_idx\n",
    "    })\n",
    "    \n",
    "    # Create per-row attack_type\n",
    "    attack_type = pd.Series(0, index=y_bin.index, dtype=int)\n",
    "    for i, row in intervals.iterrows():\n",
    "        attack_type.loc[row.start_index:row.end_index] = row.attack_id\n",
    "    \n",
    "    return attack_type, intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa582f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_type, attack_intervals = extract_attack_types(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97dece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kfold_indices(n_samples, k=5, seed=42): # generates indices for k-fold cross-validation.\n",
    "    np.random.seed(seed) # seed for reproducibility\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices) # only normal rows\n",
    "    fold_sizes = np.full(k, n_samples // k, dtype=int)\n",
    "    fold_sizes[: n_samples % k] += 1 # distribute the samples as evenly as possible\n",
    "    current = 0\n",
    "    folds = []\n",
    "    for fold_size in fold_sizes:\n",
    "        start, stop = current, current + fold_size\n",
    "        folds.append(indices[start:stop])\n",
    "        current = stop\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2b5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_1_split(X, y, k=5, seed=42, balance_attacks=False):\n",
    "    \"\"\"\n",
    "    Scenario 1:\n",
    "      Train on normal data only.\n",
    "      Test on normal (current fold) + all attack samples.\n",
    "    \"\"\"\n",
    "    normal_idx = np.where(y == 0)[0] # returns indices where condition is met ( taking normal data indices)\n",
    "    attack_idx = np.where(y == 1)[0]\n",
    "    folds = make_kfold_indices(len(normal_idx), k, seed)\n",
    "\n",
    "    for fold_idx in range(k):\n",
    "        test_normal_idx = normal_idx[folds[fold_idx]] # pick normal test samples for current fold\n",
    "        train_normal_idx = np.setdiff1d(normal_idx, test_normal_idx) # pick whatever normal samples are not in test set\n",
    "\n",
    "        # Optionally balance attack samples in test\n",
    "        if balance_attacks:\n",
    "            n_attack = len(test_normal_idx)\n",
    "            attack_sample_idx = np.random.choice(attack_idx, n_attack, replace=False)\n",
    "        else:\n",
    "            attack_sample_idx = attack_idx\n",
    "\n",
    "        test_idx = np.concatenate([test_normal_idx, attack_sample_idx]) # both normal and attack samples in test set\n",
    "        train_idx = train_normal_idx # only normal samples in train set\n",
    "\n",
    "        yield fold_idx, train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc79ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_2_split(X, y, attack_type, attack_intervals, k=5, seed=42):\n",
    "    \"\"\"\n",
    "    Scenario 2:\n",
    "      - Train on normal + (nâˆ’1) attack types (i.e., exclude one attack type)\n",
    "      - Test on normal fold + all attack types\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    normal_idx = np.where(y == 0)[0]\n",
    "    attack_ids = attack_intervals[\"attack_id\"].unique()\n",
    "\n",
    "    folds = make_kfold_indices(len(normal_idx), k=k, seed=seed)\n",
    "\n",
    "    for fold_idx in range(k):\n",
    "        # normal samples for this fold\n",
    "        test_normal_idx = normal_idx[folds[fold_idx]]\n",
    "        train_normal_idx = np.setdiff1d(normal_idx, test_normal_idx)\n",
    "\n",
    "        # loop through each attack type to hold out\n",
    "        for held_out in attack_ids:\n",
    "\n",
    "            # training attack = all except the held_out type\n",
    "            train_attack_idx = np.where(\n",
    "                (attack_type != 0) & (attack_type != held_out)\n",
    "            )[0]\n",
    "\n",
    "            # test attack = all attack samples\n",
    "            test_attack_idx = np.where(attack_type != 0)[0]\n",
    "\n",
    "            train_idx = np.concatenate([train_normal_idx, train_attack_idx]) # train on normal + (n-1) attack types\n",
    "            test_idx = np.concatenate([test_normal_idx, test_attack_idx]) # test on normal fold + all attack types\n",
    "\n",
    "            yield fold_idx, held_out, train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4eb8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_3_split(X, y, attack_type, attack_intervals, k=5, seed=42):\n",
    "    \"\"\"\n",
    "    Scenario 3:\n",
    "      - Train on normal + exactly ONE attack type\n",
    "      - Test on normal fold + all attack types\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    normal_idx = np.where(y == 0)[0]\n",
    "    attack_ids = attack_intervals[\"attack_id\"].unique()\n",
    "    \n",
    "    folds = make_kfold_indices(len(normal_idx), k=k, seed=seed)\n",
    "\n",
    "    for fold_idx in range(k):\n",
    "        # normal fold for testing\n",
    "        test_normal_idx = normal_idx[folds[fold_idx]]\n",
    "        train_normal_idx = np.setdiff1d(normal_idx, test_normal_idx)\n",
    "\n",
    "        for selected_type in attack_ids:\n",
    "            # training attack = exactly this one type\n",
    "            train_attack_idx = np.where(attack_type == selected_type)[0]\n",
    "\n",
    "            # test attack = all attack samples\n",
    "            test_attack_idx = np.where(attack_type != 0)[0]\n",
    "\n",
    "            train_idx = np.concatenate([train_normal_idx, train_attack_idx])\n",
    "            test_idx = np.concatenate([test_normal_idx, test_attack_idx])\n",
    "\n",
    "            yield fold_idx, selected_type, train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff5acc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c71c7d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_model(X, y, model, scenario_fn):\n",
    "    for fold_idx, train_idx, test_idx in scenario_fn(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "\n",
    "        acc = np.mean(y_pred == y_test)\n",
    "        print(f\"Fold {fold_idx+1}: Accuracy={acc:.4f}, Train={len(train_idx)}, Test={len(test_idx)}\")\n",
    "\n",
    "        # print row-by-row predictions\n",
    "        # for i, pred in zip(test_idx, y_pred):\n",
    "        #     label_str = \"ATTACK\" if pred == 1 else \"NORMAL\"\n",
    "        #     print(f\"Row {i}: {label_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import run_OneClassSVM\n",
    "results = run_OneClassSVM(X, y, scenario_1_split)\n",
    "# Access example\n",
    "for fold_idx, test_idx, y_pred, y_test in results:\n",
    "    print(f\"Fold {fold_idx}: detected {y_pred.sum()} attacks\")\n",
    "\n",
    "for idx, pred in zip(test_idx, y_pred):\n",
    "    print(f\"Row {idx}: {'ATTACK' if pred==1 else 'NORMAL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .models import run_EllipticEnvelope\n",
    "results_ee = run_EllipticEnvelope(X, y, scenario_1_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bca4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .models import run_LOF\n",
    "results_lof = run_LOF(X, y, scenario_1_split)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
